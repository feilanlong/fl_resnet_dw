{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import models,transforms,datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import copy\n",
    "import datetime\n",
    "import os\n",
    "from resnet18_dw_diy import resnet18_dw_diy\n",
    "from resnet18_no_pre_diy import resnet18_no_pre_diy\n",
    "from train_model import train_model\n",
    "from count_macs_parm import compute_params_flops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "pic_size = 224\n",
    "root = \"malevis_train_val_224x224\"\n",
    "num_class = 26\n",
    "num_epochs = 20\n",
    "\n",
    "train_transforms = transforms.Compose([transforms.Resize((pic_size, pic_size)),\n",
    "                                       transforms.RandomHorizontalFlip(),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       ])\n",
    "val_transforms = transforms.Compose([transforms.Resize((pic_size, pic_size)),\n",
    "                                     transforms.ToTensor()\n",
    "                                     ])\n",
    "train_dataset = datasets.ImageFolder(root = os.path.join(root,\"train\"),transform = train_transforms)\n",
    "test_dataset = datasets.ImageFolder(root = os.path.join(root,\"val\"),transform = val_transforms)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset)\n",
    "data_loaders = {'train': train_loader, 'val': test_loader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "macs, params = 1.824G, 11.190M\n",
      "macs, params = 346.241M, 1.463M\n"
     ]
    }
   ],
   "source": [
    "model = resnet18_no_pre_diy()\n",
    "compute_params_flops(cnn=model, n_channels=3, n_size=pic_size)\n",
    "model = resnet18_dw_diy()\n",
    "compute_params_flops(cnn=model, n_channels=3, n_size=pic_size)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.1) # Decay LR by a factor of 0.1 every 1 epochs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"开始训练！\")\n",
    "train_model(device=device,model=model, pic_size=pic_size,data_loaders=data_loaders,criterion=criterion, optimizer=optimizer, scheduler=exp_lr_scheduler, num_epochs=num_epochs)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6d90897fae5005298301a9a4fa27aafe85d072e307aae8642dc72bd25eb83c53"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
